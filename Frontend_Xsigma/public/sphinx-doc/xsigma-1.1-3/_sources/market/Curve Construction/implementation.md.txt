# Implementation / Numerical Schema Description





## Overview

The implementation of the New Curve Framework (NCF) from Our project focuses on computational efficiency, numerical stability, and production-grade reliability. The system is designed to handle real-time curve construction with thousands of instruments while maintaining high accuracy and performance.

## Core Curve Construction Architecture

The curve construction framework is built around several key classes that work together to provide efficient and accurate curve building capabilities.

**Main Curve Calibration Class**:
```cpp
namespace xsigma {
    class curve_calibration {
    public:
        // Constructor for curve calibration
        ANALYTICS_API curve_calibration(
            const datetime& valuation_date,
            const datetime& base_date,
            const ptr_const<curve_calibration_config>& config,
            const ptr_const<curve_calibration_targets>& targets,
            const any_container& market,
            const xsigma_set<any_id>& precalibrated_ids
        );

        ANALYTICS_API ~curve_calibration();

        // Main calibration method implementing the optimization framework
        ANALYTICS_API void calibrate();

        // Bootstrap curves using sequential method
        ANALYTICS_API void bootstrap_curves(any_container_precomputed& market_precomputed);

        // Optimize curves using global solver
        ANALYTICS_API void optimize_curves(any_container_precomputed& market_precomputed);

        // Bootstrap single curve at dependency index
        ANALYTICS_API void bootstrap_single_curve(
            any_container_precomputed& market_precomputed,
            size_t dependency_index);

        // Optimize single curve at dependency index
        ANALYTICS_API void optimize_single_curve(
            any_container_precomputed& market_precomputed,
            xsigma_set<any_id>& precalibrated_ids,
            size_t dependency_index);

        // Create and add curve to market container
        ANALYTICS_API void create_and_add_curve(
            const any_id& id,
            const curve_calibration_dates& node_dates,
            const ptr_const<discount_curve>& base_curve,
            const std::vector<double>& rates);

    private:
        datetime valuation_date_;
        datetime base_date_;
        ptr_const<curve_calibration_config> config_;
        ptr_const<curve_calibration_targets> targets_;
        any_container market_;
        xsigma_set<any_id> precalibrated_ids_;

        // Internal calibration infrastructure
        std::vector<xsigma_set<any_id>> stage_dependencies_;
        std::vector<size_t> num_of_targets_;
    };
}
```

*The main calibration class orchestrates the entire curve construction process. It supports both bootstrapping (sequential curve building) and global optimization approaches, depending on the configuration. The class manages dependencies between curves and ensures proper sequencing of the calibration process.*

**Discount Curve Hierarchy**:
```cpp
namespace xsigma {
    // Base discount curve class providing common interface
    class discount_curve : public market_data {
    public:
        virtual ~discount_curve() = default;

        // Core discount factor methods
        MARKET_API std::vector<double> dfs(const std::vector<datetime>& dates) const;
        MARKET_API double df(const datetime& to) const;
        virtual double log_df(const datetime& start, const datetime& end) const = 0;
        virtual double df(const datetime& start, const datetime& end) const = 0;

        // Algorithmic differentiation support for optimization
        virtual void df_aad(
            const double value_aad,
            const datetime& start_date,
            const datetime& end_date,
            double* state_parameters_aad) const;

        // Vectorized operations for performance
        MARKET_API virtual void discounting(vector<double>& output, const datetime& to) const;
        MARKET_API virtual void log_df(
            vector<double>& output,
            const datetime& from,
            const datetime& to) const;
    };

    // Interpolated discount curve implementation
    class discount_curve_interpolated final : public discount_curve {
    public:
        MARKET_API discount_curve_interpolated(
            const datetime& valuation_date,
            std::vector<datetime> dates,
            std::vector<double> log_dfs,
            std::array<datetime, 2> switch_points,
            std::array<interpolation_enum, 3> interpolation_type);

        MARKET_API ~discount_curve_interpolated() override;

        MARKET_API double df(
            const datetime& start_date,
            const datetime& end_date) const override;

        MARKET_API double log_df(
            const datetime& start_date,
            const datetime& end_date) const override;

        MARKET_API void df_aad(
            const double value_aad,
            const datetime& start_date,
            const datetime& end_date,
            double* state_parameters_aad) const override;

    private:
        // Internal interpolation infrastructure
        ptr_const<interpolator<vector<double>, double, double>> interpolator_;
        std::vector<datetime> dates_;
        vector<double> log_dfs_;
    };

    // Composite discount curve for multi-curve construction
    class discount_curve_composite final : public discount_curve {
    public:
        MARKET_API discount_curve_composite(
            const datetime& valuation_date,
            const ptr_const<discount_curve>& base_curve,
            const ptr_const<discount_curve>& spread_curve);

        MARKET_API double df(
            const datetime& start_date,
            const datetime& end_date) const override;

        MARKET_API double log_df(
            const datetime& start_date,
            const datetime& end_date) const override;

    private:
        ptr_const<discount_curve> base_curve_;
        ptr_const<discount_curve> spread_curve_;
    };
}
```

*The discount curve hierarchy provides a flexible foundation for different curve types. The interpolated curve handles the mathematical interpolation, while the composite curve enables multi-curve construction by combining base and spread curves. All classes support AAD for exact derivative computation during optimization.*

## Algorithmic Differentiation Implementation

### Forward Mode AD

The framework implements forward mode algorithmic differentiation (AD) for exact Jacobian computation. This approach provides several advantages over finite difference methods:

**Accuracy**: Machine precision derivatives without truncation errors
**Efficiency**: Jacobian computation scales linearly with number of parameters
**Stability**: No numerical issues from finite difference step size selection

### AD Implementation Details

**Dual Number Arithmetic**:
Each variable is represented as a dual number $(a, a')$ where:
- $a$ is the function value
- $a'$ is the derivative value

**Arithmetic Operations**:
- Addition: $(a, a') + (b, b') = (a + b, a' + b')$
- Multiplication: $(a, a') \times (b, b') = (ab, a'b + ab')$
- Division: $(a, a') / (b, b') = (a/b, (a'b - ab')/b^2)$
- Exponential: $\exp(a, a') = (\exp(a), a'\exp(a))$
- Logarithm: $\log(a, a') = (\log(a), a'/a)$

## Interpolation Infrastructure from Our Project

**Interpolation Factory and Types**:
```cpp
namespace xsigma {
    // Available interpolation methods
    enum class interpolation_enum : int {
        LINEAR                   = 0,
        CUBIC_HERMITE            = 1,
        CUBIC_SPLINE             = 2,
        PIECEWISE_CONSTANT_LEFT  = 3,
        PIECEWISE_CONSTANT_RIGHT = 4,
        LINEAR_EXPONENTIAL       = 5,
        GEOMETRIC                = 6,
        GEOMETRIC_AVERAGE        = 7,
        MEAN_REVERTING          = 7,  // For volatility interpolation
        FIXED_STRIKE            = 8   // For volatility interpolation
    };

    // Interpolator factory for creating interpolation objects
    template <typename Container, typename T, typename S>
    class interpolator_factory {
    public:
        static ptr_const<interpolator<Container, T, S>> create_ptr(
            interpolation_enum type,
            std::vector<T>&& x,
            Container&& y,
            cubic_spline_condition_enum left_condition = cubic_spline_condition_enum::SECOND_DERIVATIVE,
            S left_value = 0,
            cubic_spline_condition_enum right_condition = cubic_spline_condition_enum::SECOND_DERIVATIVE,
            S right_value = 0) {

            switch (type) {
            case interpolation_enum::LINEAR:
                return util::make_ptr_const<interpolator_linear<Container, T, S>>(
                    std::move(x), std::move(y));

            case interpolation_enum::LINEAR_EXPONENTIAL:
                return util::make_ptr_const<interpolator_linear_exponential<Container, T, S>>(
                    std::move(x), std::move(y));

            case interpolation_enum::CUBIC_SPLINE:
                return util::make_ptr_const<interpolator_cubic_spline<Container, T, S>>(
                    std::move(x), std::move(y), left_condition, left_value,
                    right_condition, right_value);

            case interpolation_enum::CUBIC_HERMITE:
                return util::make_ptr_const<interpolator_cubic_hermite<Container, T, S>>(
                    std::move(x), std::move(y));

            case interpolation_enum::PIECEWISE_CONSTANT_LEFT:
                return util::make_ptr_const<interpolator_piecewise_constant_left<Container, T, S>>(
                    std::move(x), std::move(y));

            case interpolation_enum::GEOMETRIC:
                return util::make_ptr_const<interpolator_geometric<Container, T, S>>(
                    std::move(x), std::move(y));

            default:
                XSIGMA_THROW("Unsupported interpolation type");
            }
        }
    };

    // Composite interpolator for multi-region curves
    template<typename Container, typename T, typename S, typename... Interpolators>
    class interpolator_composite {
    public:
        interpolator_composite(
            std::array<T, sizeof...(Interpolators) - 1> switch_points,
            Interpolators&&... interpolators)
            : switch_points_(switch_points),
              interpolators_(std::forward<Interpolators>(interpolators)...) {}

        S interpolate(const T& x) const {
            // Find appropriate interpolator based on switch points
            size_t region = find_region(x);
            return get_interpolator(region).interpolate(x);
        }

    private:
        std::array<T, sizeof...(Interpolators) - 1> switch_points_;
        std::tuple<Interpolators...> interpolators_;

        size_t find_region(const T& x) const {
            for (size_t i = 0; i < switch_points_.size(); ++i) {
                if (x < switch_points_[i]) return i;
            }
            return switch_points_.size();
        }
    };
}
```

### Jacobian Matrix Construction from Our Project

The Jacobian matrix is built incrementally during the forward pass using algorithmic differentiation:

```cpp
namespace xsigma {
    // Jacobian Matrix Construction with AAD
    void curve_calibration::calculate_jacobian_aad(
        const std::vector<double>& parameters,
        matrix<double>& jacobian) const {

        const size_t num_params = parameters.size();
        const size_t num_targets = jacobian.rows();

        // Initialize jacobian matrix
        jacobian.resize(num_targets, num_params);

        for (size_t i = 0; i < num_params; ++i) {
            // Set seed vector for parameter i
            std::vector<double> seed(num_params, 0.0);
            seed[i] = 1.0;  // ∂xi/∂xi = 1, ∂xj/∂xi = 0 for j ≠ i

            // Evaluate objective function with AAD
            std::vector<double> residuals(num_targets);
            objective_function_aad(parameters, residuals, seed.data());

            // Store derivatives as column i of Jacobian matrix
            for (size_t j = 0; j < num_targets; ++j) {
                jacobian(j, i) = residuals[j];
            }
        }
    }
}
```

**Key Properties:**
- **Sparsity**: Most elements are zero due to local instrument sensitivities
- **Efficiency**: Forward mode AD scales linearly with number of parameters
- **Accuracy**: Machine precision derivatives without truncation errors

## Optimization Algorithm Implementation

### Levenberg-Marquardt Algorithm

The core optimization uses a robust implementation of the Levenberg-Marquardt algorithm:

**Algorithm Steps**:
1. **Initialize**: Set initial curve values and damping parameter μ
2. **Evaluate**: Compute residuals and Jacobian matrix
3. **Solve**: Solve linear system $(J^TJ + μI)h = -J^Tr$
4. **Update**: Apply step with adaptive damping
5. **Check**: Test convergence criteria
6. **Iterate**: Repeat until convergence

### Damping Parameter Adaptation

The damping parameter μ is adapted based on step acceptance using the following strategy:

```cpp
// Adaptive Damping Algorithm
double evaluate_step_quality(const Vector& current_residual,
                            const Vector& new_residual) {
    double current_cost = 0.5 * current_residual.squaredNorm();
    double new_cost = 0.5 * new_residual.squaredNorm();
    return (current_cost - new_cost) / current_cost;
}

void adapt_damping_parameter(double step_quality, double& mu) {
    if (step_quality > 0.75) {
        mu = mu / 3.0;  // Excellent step - decrease damping significantly
    } else if (step_quality > 0.25) {
        mu = mu / 2.0;  // Good step - decrease damping moderately
    } else if (step_quality < 0.0) {
        mu = mu * 2.0;  // Poor step - increase damping and retry
    }
    // Maintain current damping for marginal steps (0.0 ≤ quality ≤ 0.25)
}
```

**Adaptation Strategy:**
- **Excellent steps** (>75% improvement): Aggressive damping reduction
- **Good steps** (25-75% improvement): Moderate damping reduction
- **Marginal steps** (0-25% improvement): Maintain current damping
- **Poor steps** (<0% improvement): Increase damping and reject step

### Linear System Solution

The linear system $(J^TJ + μI)h = -J^Tr$ is solved using:

**Cholesky Decomposition**: For well-conditioned systems
**QR Decomposition**: For rank-deficient or ill-conditioned systems
**Iterative Methods**: For very large systems (GMRES, BiCGSTAB)

## Data Structures and Memory Management

### Curve Representation

**Node Storage**:
```cpp
struct CurveNode {
    Date date;
    double value;        // discount factor or forward rate
    double derivative;   // for AD computation
};

class Curve {
    std::vector<CurveNode> nodes;
    InterpolationMethod interpolator;
    CurveType type;
};
```

**Sparse Matrix Storage**:
The Jacobian matrix is stored in compressed sparse row (CSR) format for memory efficiency:

```cpp
struct SparseMatrix {
    std::vector<double> values;
    std::vector<int> column_indices;
    std::vector<int> row_pointers;
};
```

### Memory Pool Management

**Object Pooling**: Reuse of temporary objects to reduce allocation overhead
**Memory Alignment**: Optimized memory layout for cache efficiency
**RAII Principles**: Automatic resource management for exception safety

## Interpolation Implementation

### Primary Interpolation Methods

**Log-Linear on Discount Factors**:
```cpp
double interpolate_log_linear(double t, const CurveNode& left, const CurveNode& right) {
    double alpha = (t - left.date) / (right.date - left.date);
    return exp(log(left.value) + alpha * (log(right.value) - log(left.value)));
}
```

**Linear on Forward Rates**:
```cpp
double interpolate_linear(double t, const CurveNode& left, const CurveNode& right) {
    double alpha = (t - left.date) / (right.date - left.date);
    return left.value + alpha * (right.value - left.value);
}
```

**Cubic Spline**:
Implementation uses natural cubic splines with second derivative boundary conditions.

### Hybrid Interpolation

The framework supports different interpolation methods for different curve regions:

```cpp
class HybridInterpolator {
    std::vector<std::pair<Date, InterpolationMethod>> regions;
    
    double interpolate(Date t, const std::vector<CurveNode>& nodes) {
        auto method = find_interpolation_method(t);
        return method->interpolate(t, nodes);
    }
};
```

## Numerical Stability Enhancements

### Scaling and Conditioning

**Instrument Scaling**: All instruments are scaled to similar magnitudes to improve conditioning
**Parameter Scaling**: Curve parameters are scaled based on typical market ranges
**Residual Scaling**: Residuals are normalized by instrument notional or market value

### Regularization Techniques

**Tikhonov Regularization**: Added to Jacobian matrix for stability
$$J^TJ + (\mu + \lambda)I$$

**Smoothing Penalties**: Incorporated into objective function to prevent overfitting
**Parameter Bounds**: Soft constraints to keep parameters in reasonable ranges

### Convergence Monitoring

**Objective Function Tracking**: Monitor for oscillations or stagnation
**Parameter Change Monitoring**: Detect when parameters stop changing significantly
**Gradient Norm Tracking**: Ensure gradient approaches zero

## Performance Optimizations

### Computational Efficiency

**Vectorization**: Use of SIMD instructions for parallel computation
**Cache Optimization**: Data layout optimized for cache locality
**Lazy Evaluation**: Defer expensive computations until needed

### Parallel Processing

**Multi-threading**: Parallel evaluation of instrument prices
**NUMA Awareness**: Memory allocation optimized for NUMA architectures
**Load Balancing**: Dynamic work distribution across threads

### Memory Optimizations

**Memory Prefetching**: Anticipate memory access patterns
**Data Compression**: Compressed storage for large datasets
**Memory Mapping**: Use of memory-mapped files for large static data

## Error Handling and Robustness

### Exception Safety

**RAII Principles**: Automatic cleanup of resources
**Exception Specifications**: Clear documentation of exception behavior
**Rollback Mechanisms**: Ability to restore previous state on failure

### Numerical Error Detection

**NaN/Inf Detection**: Comprehensive checking for invalid floating-point values
**Overflow Protection**: Guards against arithmetic overflow
**Underflow Handling**: Graceful handling of very small numbers

### Fallback Mechanisms

**Alternative Algorithms**: Fallback to different optimization methods
**Simplified Models**: Reduced complexity models for difficult cases
**Manual Intervention**: Hooks for manual override in extreme cases

## Quality Control Implementation

### Repricing Verification

**Automatic Checking**: All instruments automatically repriced after construction
**Tolerance Monitoring**: Configurable tolerances for different instrument types
**Error Reporting**: Detailed reporting of repricing failures

### Interpolation Verification

**Exact Reproduction**: Verify interpolation exactly reproduces node values
**Smoothness Checking**: Verify continuity and differentiability requirements
**Monotonicity Checks**: Ensure appropriate monotonicity properties

### Performance Monitoring

**Timing Instrumentation**: Detailed timing of all major operations
**Memory Usage Tracking**: Monitor memory consumption patterns
**Convergence Statistics**: Track optimization convergence behavior

## Production Deployment Considerations

### Scalability

**Horizontal Scaling**: Support for distributed curve construction
**Vertical Scaling**: Efficient use of multi-core systems
**Load Testing**: Comprehensive testing under production loads

### Reliability

**Fault Tolerance**: Graceful handling of system failures
**Data Validation**: Comprehensive input data validation
**Monitoring Integration**: Integration with production monitoring systems

### Maintainability

**Modular Design**: Clear separation of concerns
**Configuration Management**: Externalized configuration parameters
**Logging and Diagnostics**: Comprehensive logging for troubleshooting

## Integration with External Systems

### Market Data Feeds

**Real-time Integration**: Support for real-time market data updates
**Data Quality Checks**: Validation of incoming market data
**Fallback Data Sources**: Multiple data source support for reliability

### Risk Systems

**Jacobian Export**: Efficient export of Jacobian matrices for risk systems
**Shocked Curve Generation**: Support for risk scenario generation
**Performance Optimization**: Optimized for high-frequency risk calculations

### Pricing Systems

**Curve Caching**: Efficient caching mechanisms for repeated queries
**Query Optimization**: Optimized curve query interfaces
**Batch Processing**: Support for batch curve construction and queries
